{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global parameters\n",
    "cudadir = \"/usr/common/software/cuda/11.0.167\"\n",
    "homedir = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input and output dirs\n",
    "datadirs = [\"/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla\"]\n",
    "outputdir = \"/global/cfs/cdirs/m1759/yswang/results/rnn1d-tf2-noxla\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_frame(df_metrics):\n",
    "    #Copy the profile frame to make sure not to overwrite it and potentially read it in again if we screwed it up\n",
    "    selectkeys = [\"ID\", \"Precision\", \"Cell\", \"Input Shape\", \"Batch Size\", \"Time Steps\", \"Features\", \"Hidden Size\", \"Pass\", \"Name\"]\n",
    "    resultkeys = [\"Precision\", \"Cell\", \"Input Shape\", \"Batch Size\", \"Time Steps\", \"Features\", \"Hidden Size\", \"Pass\", \"Name\"]\n",
    "                                    \n",
    "    #as metricdf use df_summary\n",
    "    metricdf = df_metrics.copy()\n",
    "    #metricdf.sort_values(by=selectkeys,inplace=True)\n",
    "    #metricdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    #remove the calibration\n",
    "    metricdf = metricdf[metricdf[\"Pass\"] != \"calibrate\"]\n",
    "    profiledf = pd.DataFrame(columns=selectkeys)\n",
    "    \n",
    "    ####### Get timing information\n",
    "    ### CUDA Time\n",
    "    # get cycles\n",
    "    metricname = \"CUDA Cycles\"\n",
    "    cyclesdf = metricdf.loc[(metricdf[\"Metric Name\"]==\"sm__cycles_elapsed\") & (metricdf[\"Metric Type\"]==\"total\"),\n",
    "                           selectkeys+[\"Metric Unit\", \"Metric Value\"]].reset_index(drop=True).sort_values(by=selectkeys).rename(columns={\"Metric Value\": metricname}).copy()\n",
    "    # get rates\n",
    "    metricname = \"CUDA Rates\"\n",
    "    ratesdf = metricdf.loc[(metricdf[\"Metric Name\"]==\"sm__cycles_elapsed\") & (metricdf[\"Metric Type\"]==\"rate\"),\n",
    "                           selectkeys+[\"Metric Unit\", \"Metric Value\"]].reset_index(drop=True).sort_values(by=selectkeys).rename(columns={\"Metric Value\": metricname}).copy()\n",
    "    # check consistency\n",
    "    if not cyclesdf[['ID', 'Name']].equals(ratesdf[['ID', 'Name']]):\n",
    "        raise ValueError(\"CUDA Time data not consistent\")\n",
    "    # adjust metric unit\n",
    "    ratesdf.loc[ratesdf[\"Metric Unit\"].str.contains(\"cycle/nsecond\"), [\"CUDA Rates\"]] *= 1e9\n",
    "    # manual merge and compute CUDA Time\n",
    "    cyclesdf[\"CUDA Rates\"] = list(ratesdf[\"CUDA Rates\"])\n",
    "    cyclesdf[\"CUDA Time\"] = cyclesdf[\"CUDA Cycles\"] / cyclesdf[\"CUDA Rates\"]\n",
    "    # merge with output\n",
    "    profiledf = cyclesdf[selectkeys+['CUDA Time']].copy()\n",
    "    \n",
    "    ### Combine\n",
    "    del profiledf['ID']\n",
    "    del metricdf['ID']\n",
    "    profiledf['Invocations'] = 1\n",
    "    profiledf = profiledf.groupby(resultkeys).sum().reset_index()\n",
    "        \n",
    "    ####### Get number of FLOPs\n",
    "    \n",
    "    ### FMA FLOPs = number of FMA instructions x 2\n",
    "    metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"fma\"), [\"Metric Value\"]] *= 2\n",
    "    \n",
    "    ### FP32 FLOPs\n",
    "    metrics = ['sm__sass_thread_inst_executed_op_fadd_pred_on',\n",
    "               'sm__sass_thread_inst_executed_op_ffma_pred_on',\n",
    "               'sm__sass_thread_inst_executed_op_fmul_pred_on']\n",
    "    tmpdf = metricdf.loc[ metricdf[\"Metric Name\"].isin(metrics), resultkeys+[\"Metric Value\"] ].copy()\n",
    "    tmpdf = tmpdf.groupby(resultkeys).sum().reset_index().rename(columns={\"Metric Value\": \"FP32 FLOPs\"})\n",
    "    # merge\n",
    "    profiledf = profiledf.merge(tmpdf[resultkeys+[\"FP32 FLOPs\"]], on=resultkeys, how=\"inner\")\n",
    "    \n",
    "    ### FP16 FLOPs\n",
    "    metrics = ['sm__sass_thread_inst_executed_op_hadd_pred_on',\n",
    "               'sm__sass_thread_inst_executed_op_hfma_pred_on',\n",
    "               'sm__sass_thread_inst_executed_op_hmul_pred_on']\n",
    "    tmpdf = metricdf.loc[ metricdf[\"Metric Name\"].isin(metrics), resultkeys+[\"Metric Value\"] ].copy()\n",
    "    tmpdf = tmpdf.groupby(resultkeys).sum().reset_index().rename(columns={\"Metric Value\": \"FP16 FLOPs\"})\n",
    "    # merge\n",
    "    profiledf = profiledf.merge(tmpdf[resultkeys+[\"FP16 FLOPs\"]], on=resultkeys, how=\"inner\")\n",
    "    \n",
    "    ### TC FLOPs\n",
    "    tmpdf = metricdf.loc[ metricdf[\"Metric Name\"].str.contains(\"sm__inst_executed_pipe_tensor\"), resultkeys+[\"Metric Value\"] ].copy()\n",
    "    tmpdf = tmpdf.groupby(resultkeys).sum().reset_index().rename(columns={\"Metric Value\": \"TC FLOPs\"})\n",
    "    tmpdf[\"TC FLOPs\"] = 512 * tmpdf[\"TC FLOPs\"]\n",
    "    # merge\n",
    "    profiledf = profiledf.merge(tmpdf[resultkeys+[\"TC FLOPs\"]], on=resultkeys, how=\"inner\")\n",
    "\n",
    "    ### Total FLOPs\n",
    "    profiledf[\"FLOPs\"] = profiledf[\"FP32 FLOPs\"] + profiledf[\"FP16 FLOPs\"] + profiledf[\"TC FLOPs\"] #+ metricdf[\"FP64 FLOPs\"]\n",
    "        \n",
    "    ### FLOPs fractions\n",
    "    #profiledf[\"FP64 FLOPs Fraction\"] = profiledf[\"FP64 FLOPs\"]/profiledf[\"FLOPs\"]\n",
    "    profiledf[\"FP32 FLOPs Fraction\"] = profiledf[\"FP32 FLOPs\"]/profiledf[\"FLOPs\"]\n",
    "    profiledf[\"FP16 FLOPs Fraction\"] = profiledf[\"FP16 FLOPs\"]/profiledf[\"FLOPs\"]\n",
    "    profiledf[\"TC FLOPs Fraction\"]   = profiledf[\"TC FLOPs\"]/profiledf[\"FLOPs\"]\n",
    "    profiledf = profiledf.fillna(0.)\n",
    "\n",
    "    ####### Get number of bytes\n",
    "    \n",
    "    # adjust metric unit\n",
    "    metricdf.loc[(metricdf[\"Metric Unit\"]==\"Kbyte\"), [\"Metric Value\"]] *= 1e3\n",
    "    metricdf.loc[(metricdf[\"Metric Unit\"]==\"Mbyte\"), [\"Metric Value\"]] *= 1e6\n",
    "    metricdf.loc[(metricdf[\"Metric Unit\"]==\"Gbyte\"), [\"Metric Value\"]] *= 1e9\n",
    "    \n",
    "    ### L1 Bytes\n",
    "    #project out\n",
    "    l1df = metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"l1tex__t_bytes\"), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    l1df = l1df.groupby(resultkeys).sum().reset_index().rename(columns={\"Metric Value\": \"L1 Bytes\"})\n",
    "    # merge\n",
    "    profiledf = profiledf.merge(l1df[resultkeys+[\"L1 Bytes\"]], on=resultkeys, how=\"inner\")\n",
    "    \n",
    "    ### L2 Bytes\n",
    "    #project out\n",
    "    l2df = metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"lts__t_bytes\"), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    l2df = l2df.groupby(resultkeys).sum().reset_index().rename(columns={\"Metric Value\": \"L2 Bytes\"})\n",
    "    # merge\n",
    "    profiledf = profiledf.merge(l2df[resultkeys+[\"L2 Bytes\"]], on=resultkeys, how=\"inner\")\n",
    "    \n",
    "    ### DRAM Bytes\n",
    "    #project out\n",
    "    dramdf = metricdf.loc[metricdf[\"Metric Name\"].str.contains(\"dram__bytes\"), selectkeys+[\"Metric Value\"] ].copy()\n",
    "    dramdf = dramdf.groupby(resultkeys).sum().reset_index().rename(columns={\"Metric Value\": \"DRAM Bytes\"})\n",
    "    # merge\n",
    "    profiledf = profiledf.merge(dramdf[resultkeys+[\"DRAM Bytes\"]], on=resultkeys, how=\"inner\")\n",
    "    \n",
    "    ### Get performance\n",
    "    profiledf[\"Performance GFlop/s\"] = profiledf[\"FLOPs\"] / (profiledf[\"CUDA Time\"]*10**9)\n",
    "\n",
    "    ### Get AI\n",
    "    # L1\n",
    "    profiledf[\"L1 AI\"]        = profiledf[\"FLOPs\"]      / profiledf[\"L1 Bytes\"]\n",
    "    profiledf[\"FP32 L1 AI\"]   = profiledf[\"FP32 FLOPs\"] / profiledf[\"L1 Bytes\"]\n",
    "    profiledf[\"FP16 L1 AI\"]   = profiledf[\"FP16 FLOPs\"] / profiledf[\"L1 Bytes\"]\n",
    "    profiledf[\"TC L1 AI\"]     = profiledf[\"TC FLOPs\"]   / profiledf[\"L1 Bytes\"]\n",
    "    # L2\n",
    "    profiledf[\"L2 AI\"]        = profiledf[\"FLOPs\"]      / profiledf[\"L2 Bytes\"]\n",
    "    profiledf[\"FP32 L2 AI\"]   = profiledf[\"FP32 FLOPs\"] / profiledf[\"L2 Bytes\"]\n",
    "    profiledf[\"FP16 L2 AI\"]   = profiledf[\"FP16 FLOPs\"] / profiledf[\"L2 Bytes\"]\n",
    "    profiledf[\"TC L2 AI\"]     = profiledf[\"TC FLOPs\"]   / profiledf[\"L2 Bytes\"]\n",
    "    # DRAM\n",
    "    profiledf[\"DRAM AI\"]      = profiledf[\"FLOPs\"]      / profiledf[\"DRAM Bytes\"]\n",
    "    profiledf[\"FP32 DRAM AI\"] = profiledf[\"FP32 FLOPs\"] / profiledf[\"DRAM Bytes\"]\n",
    "    profiledf[\"FP16 DRAM AI\"] = profiledf[\"FP16 FLOPs\"] / profiledf[\"DRAM Bytes\"]\n",
    "    profiledf[\"TC DRAM AI\"]   = profiledf[\"TC FLOPs\"]   / profiledf[\"DRAM Bytes\"]\n",
    "    \n",
    "    ### Cleanup\n",
    "    profiledf.sort_values(by=resultkeys).reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return profiledf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the files\n",
    "files = []\n",
    "for datadir in datadirs:\n",
    "    files += [ os.path.join(datadir,x) for x in os.listdir(datadir) if ((os.path.splitext(x)[-1] == \".ncu-rep\"))]\n",
    "\n",
    "#recs\n",
    "records = []\n",
    "\n",
    "#build feature list:\n",
    "for path in files:\n",
    "    \n",
    "    #filename\n",
    "    file = os.path.basename(path)\n",
    "    \n",
    "    #path\n",
    "    path = os.path.dirname(path)\n",
    "    \n",
    "    #splitup\n",
    "    splt = file.split(\".\")\n",
    "    \n",
    "    prefix = \".\".join(splt[0:-1])\n",
    "    \n",
    "    #append to records\n",
    "    records.append({\"prefix\": prefix, \"file\": os.path.join(path, file)})\n",
    "\n",
    "#put in df\n",
    "recorddf = pd.DataFrame(records).sort_values([\"prefix\"])\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#display(recorddf[\"prefix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x64.nneu_64.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x64.nneu_64.pass_forward.noxla.ncu-rep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/common/software/python/3.7-anaconda-2019.10/lib/python3.7/site-packages/pandas/core/indexing.py:1418: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x32.nneu_32.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x32.nneu_32.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x128.nneu_128.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x128.nneu_128.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x128.nneu_64.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x128.nneu_64.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x64.nneu_128.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x64.nneu_128.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x64.nneu_64.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x64.nneu_64.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x32.nneu_64.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x32.nneu_64.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x32.nneu_128.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x32.nneu_128.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x128.nneu_32.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x128.nneu_32.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_64x32x32.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_64x32x32.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x64.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x64.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x32.nneu_128.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x32.nneu_128.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x128.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x128.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x64.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x64.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x128.nneu_64.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x128.nneu_64.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x128.nneu_128.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x128.nneu_128.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x64.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x64.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_32.celltype_lstm.input_128x32x32.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_32.celltype_lstm.input_128x32x32.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x32.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x32.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x64.nneu_32.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x64.nneu_32.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_256x32x32.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_256x32x32.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x128.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x128.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x128.nneu_32.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x128.nneu_32.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x64.nneu_32.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x64.nneu_32.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x32.nneu_32.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x32.nneu_32.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x128.nneu_64.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x128.nneu_64.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x32.nneu_64.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x32.nneu_64.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x64.nneu_128.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x64.nneu_128.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x64.nneu_128.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x64.nneu_128.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x32.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x32.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x128.nneu_128.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x128.nneu_128.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_128x32x32.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_128x32x32.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x128.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x128.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_32.celltype_lstm.input_256x32x32.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_32.celltype_lstm.input_256x32x32.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x128.nneu_32.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x128.nneu_32.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x32.nneu_32.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x32.nneu_32.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x32.nneu_64.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x32x32.nneu_64.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_32.celltype_lstm.input_32x32x32.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_32.celltype_lstm.input_32x32x32.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x32.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x32.nneu_16.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x64.nneu_64.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x128x64.nneu_64.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x64.nneu_32.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x64.nneu_32.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x32.nneu_128.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_16.celltype_lstm.input_32x64x32.nneu_128.pass_forward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_32.celltype_lstm.input_64x32x32.nneu_16.pass_backward.noxla.ncu-rep\n",
      "/global/cfs/cdirs/m1759/yswang/data/rnn1d-tf2-noxla/tf2.fp_32.celltype_lstm.input_64x32x32.nneu_16.pass_forward.noxla.ncu-rep\n"
     ]
    }
   ],
   "source": [
    "#group by prefixes and files\n",
    "all_prefixes = set([x.split(\".pass\")[0] for x in recorddf[\"prefix\"]])\n",
    "xla_list = set([x.split(\".\")[-1] for x in recorddf[\"prefix\"]])\n",
    "if (len(xla_list) != 1):\n",
    "    raise RuntimeError(\"too many xla options.\")\n",
    "xla = xla_list.pop()\n",
    "\n",
    "all_passes = set([x.split(\".pass_\")[1].replace(\".pass_\",\"\") for x in recorddf[\"prefix\"].unique()])\n",
    "all_passes = set([x.split(\".\")[0] for x in all_passes])\n",
    "\n",
    "#metrics\n",
    "df_profiles = []\n",
    "\n",
    "for pref in all_prefixes:\n",
    "    \n",
    "    #set empty lists\n",
    "    df_times = []\n",
    "    df_timeline = []\n",
    "    df_summary = []\n",
    "    \n",
    "    #print prefix\n",
    "    #print(pref)\n",
    "    \n",
    "    #loop over passes\n",
    "    df_times = []\n",
    "    df_metrics = []\n",
    "    for pas in all_passes:\n",
    "        if pas == 'calibrate':\n",
    "            continue\n",
    "        \n",
    "        #project frame\n",
    "        files = recorddf.loc[ recorddf[\"prefix\"] == pref + \".pass_\" + pas + \".\" + xla, \"file\" ].values\n",
    "        \n",
    "        #project the invididual files\n",
    "        metricfile = [x for x in files if x.endswith(\".ncu-rep\")][0]\n",
    "        print(metricfile)\n",
    "            \n",
    "        #get the parameters from the filename\n",
    "        parameters = parse_filename_nsight(os.path.basename(metricfile))\n",
    "        #print(parameters)\n",
    "            \n",
    "        #metrics\n",
    "        metricdf = import_nsight_metric(metricfile, cuda_dir=cudadir)\n",
    "        for key in parameters:\n",
    "            metricdf[key] = parameters[key]\n",
    "\n",
    "        #fuse read/write metrics together:\n",
    "        unique_metrics = metricdf[\"Metric Name\"].unique()\n",
    "        \n",
    "        unique_metrics = set([x.replace(\".sum\",\"\").replace(\".per_second\",\"\").replace(\".avg\",\"\") for x in unique_metrics])\n",
    "        #add the metric type\n",
    "        metricdf[\"Metric Type\"] = \"total\"\n",
    "        #rate\n",
    "        metricdf.loc[ metricdf[ \"Metric Name\" ].str.contains(\".per_second\"), \"Metric Type\" ] = \"rate\"\n",
    "                \n",
    "        for metric in unique_metrics:\n",
    "            metricdf.loc[ metricdf[ \"Metric Name\"].str.startswith(metric), \"Metric Name\" ] = metric\n",
    "                \n",
    "        #append to DF:\n",
    "        df_metrics.append(metricdf)\n",
    "    \n",
    "    metricdf = pd.concat(df_metrics)\n",
    "    \n",
    "    #compute the profile\n",
    "    profiledf = transpose_frame(metricdf)\n",
    "    df_profiles.append(profiledf)\n",
    "\n",
    "#concat everything\n",
    "profiledf = pd.concat(df_profiles)\n",
    "profiledf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Cell</th>\n",
       "      <th>Input Shape</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Time Steps</th>\n",
       "      <th>Features</th>\n",
       "      <th>Hidden Size</th>\n",
       "      <th>Pass</th>\n",
       "      <th>Name</th>\n",
       "      <th>CUDA Time</th>\n",
       "      <th>...</th>\n",
       "      <th>FP16 L1 AI</th>\n",
       "      <th>TC L1 AI</th>\n",
       "      <th>L2 AI</th>\n",
       "      <th>FP32 L2 AI</th>\n",
       "      <th>FP16 L2 AI</th>\n",
       "      <th>TC L2 AI</th>\n",
       "      <th>DRAM AI</th>\n",
       "      <th>FP32 DRAM AI</th>\n",
       "      <th>FP16 DRAM AI</th>\n",
       "      <th>TC DRAM AI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FP16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>32x64x64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>backward</td>\n",
       "      <td>_ZN10tensorflow87_GLOBAL__N__63_tmpxft_000027e...</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FP16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>32x64x64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>backward</td>\n",
       "      <td>_ZN10tensorflow93_GLOBAL__N__69_tmpxft_0000243...</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FP16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>32x64x64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>backward</td>\n",
       "      <td>void Eigen::internal::EigenMetaKernel&lt;Eigen::T...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FP16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>32x64x64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>backward</td>\n",
       "      <td>void Eigen::internal::EigenMetaKernel&lt;Eigen::T...</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095226</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>FP16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>32x64x64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>backward</td>\n",
       "      <td>void Eigen::internal::EigenMetaKernel&lt;Eigen::T...</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285536</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2038</td>\n",
       "      <td>FP32</td>\n",
       "      <td>lstm</td>\n",
       "      <td>64x32x32</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>forward</td>\n",
       "      <td>void tensorflow::functor::FillPhiloxRandomKern...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.564324</td>\n",
       "      <td>7.564324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.454472</td>\n",
       "      <td>87.454472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2039</td>\n",
       "      <td>FP32</td>\n",
       "      <td>lstm</td>\n",
       "      <td>64x32x32</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>forward</td>\n",
       "      <td>void tensorflow::functor::FillPhiloxRandomKern...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247008</td>\n",
       "      <td>0.247008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.623143</td>\n",
       "      <td>2.623143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>FP32</td>\n",
       "      <td>lstm</td>\n",
       "      <td>64x32x32</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>forward</td>\n",
       "      <td>void tensorflow::functor::SwapDimension1And2In...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2041</td>\n",
       "      <td>FP32</td>\n",
       "      <td>lstm</td>\n",
       "      <td>64x32x32</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>forward</td>\n",
       "      <td>volta_sgemm_32x128_nn</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.220857</td>\n",
       "      <td>5.220857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.920494</td>\n",
       "      <td>13.920494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2042</td>\n",
       "      <td>FP32</td>\n",
       "      <td>lstm</td>\n",
       "      <td>64x32x32</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>forward</td>\n",
       "      <td>volta_sgemm_32x32_sliced1x4_nn</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.580444</td>\n",
       "      <td>2.580444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.025947</td>\n",
       "      <td>9.025947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2043 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Precision  Cell Input Shape  Batch Size  Time Steps  Features  \\\n",
       "0         FP16  lstm    32x64x64          32          64        64   \n",
       "1         FP16  lstm    32x64x64          32          64        64   \n",
       "2         FP16  lstm    32x64x64          32          64        64   \n",
       "3         FP16  lstm    32x64x64          32          64        64   \n",
       "4         FP16  lstm    32x64x64          32          64        64   \n",
       "...        ...   ...         ...         ...         ...       ...   \n",
       "2038      FP32  lstm    64x32x32          64          32        32   \n",
       "2039      FP32  lstm    64x32x32          64          32        32   \n",
       "2040      FP32  lstm    64x32x32          64          32        32   \n",
       "2041      FP32  lstm    64x32x32          64          32        32   \n",
       "2042      FP32  lstm    64x32x32          64          32        32   \n",
       "\n",
       "      Hidden Size      Pass  \\\n",
       "0              64  backward   \n",
       "1              64  backward   \n",
       "2              64  backward   \n",
       "3              64  backward   \n",
       "4              64  backward   \n",
       "...           ...       ...   \n",
       "2038           16   forward   \n",
       "2039           16   forward   \n",
       "2040           16   forward   \n",
       "2041           16   forward   \n",
       "2042           16   forward   \n",
       "\n",
       "                                                   Name  CUDA Time  ...  \\\n",
       "0     _ZN10tensorflow87_GLOBAL__N__63_tmpxft_000027e...   0.000403  ...   \n",
       "1     _ZN10tensorflow93_GLOBAL__N__69_tmpxft_0000243...   0.000034  ...   \n",
       "2     void Eigen::internal::EigenMetaKernel<Eigen::T...   0.000006  ...   \n",
       "3     void Eigen::internal::EigenMetaKernel<Eigen::T...   0.001865  ...   \n",
       "4     void Eigen::internal::EigenMetaKernel<Eigen::T...   0.000625  ...   \n",
       "...                                                 ...        ...  ...   \n",
       "2038  void tensorflow::functor::FillPhiloxRandomKern...   0.000009  ...   \n",
       "2039  void tensorflow::functor::FillPhiloxRandomKern...   0.000014  ...   \n",
       "2040  void tensorflow::functor::SwapDimension1And2In...   0.000006  ...   \n",
       "2041                              volta_sgemm_32x128_nn   0.000289  ...   \n",
       "2042                     volta_sgemm_32x32_sliced1x4_nn   0.000374  ...   \n",
       "\n",
       "      FP16 L1 AI  TC L1 AI     L2 AI  FP32 L2 AI  FP16 L2 AI  TC L2 AI  \\\n",
       "0       0.000000       0.0  0.000000    0.000000    0.000000       0.0   \n",
       "1       0.000000       0.0  0.000000    0.000000    0.000000       0.0   \n",
       "2       0.010417       0.0  0.000287    0.000000    0.000287       0.0   \n",
       "3       0.083320       0.0  0.058603    0.000000    0.058603       0.0   \n",
       "4       0.249959       0.0  0.175777    0.000000    0.175777       0.0   \n",
       "...          ...       ...       ...         ...         ...       ...   \n",
       "2038    0.000000       0.0  7.564324    7.564324    0.000000       0.0   \n",
       "2039    0.000000       0.0  0.247008    0.247008    0.000000       0.0   \n",
       "2040    0.000000       0.0  0.000000    0.000000    0.000000       0.0   \n",
       "2041    0.000000       0.0  5.220857    5.220857    0.000000       0.0   \n",
       "2042    0.000000       0.0  2.580444    2.580444    0.000000       0.0   \n",
       "\n",
       "        DRAM AI  FP32 DRAM AI  FP16 DRAM AI  TC DRAM AI  \n",
       "0      0.000000      0.000000      0.000000         0.0  \n",
       "1      0.000000      0.000000      0.000000         0.0  \n",
       "2      0.000372      0.000000      0.000372         0.0  \n",
       "3      0.095226      0.000000      0.095226         0.0  \n",
       "4      0.285536      0.000000      0.285536         0.0  \n",
       "...         ...           ...           ...         ...  \n",
       "2038  87.454472     87.454472      0.000000         0.0  \n",
       "2039   2.623143      2.623143      0.000000         0.0  \n",
       "2040   0.000000      0.000000      0.000000         0.0  \n",
       "2041  13.920494     13.920494      0.000000         0.0  \n",
       "2042   9.025947      9.025947      0.000000         0.0  \n",
       "\n",
       "[2043 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(profiledf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute AI Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum over all kernels\n",
    "combinedselectkeys = [\"Precision\", \"Cell\", \"Input Shape\", \"Batch Size\", \"Time Steps\", \"Features\", \"Hidden Size\", \"Pass\"]\n",
    "\n",
    "#copy profiledf\n",
    "combineddf = profiledf.copy()\n",
    "\n",
    "#sum up\n",
    "combineddf = combineddf.groupby(by=combinedselectkeys).sum()\n",
    "\n",
    "\n",
    "#the flop fractions need to be recomputed\n",
    "combineddf[\"FP32 FLOPs Fraction\"] = combineddf[\"FP32 FLOPs\"] / combineddf[\"FLOPs\"]\n",
    "combineddf[\"FP16 FLOPs Fraction\"] = combineddf[\"FP16 FLOPs\"] / combineddf[\"FLOPs\"]\n",
    "combineddf[\"TC FLOPs Fraction\"]   = combineddf[\"TC FLOPs\"]   / combineddf[\"FLOPs\"]\n",
    "\n",
    "### Get performance\n",
    "combineddf[\"Performance GFlop/s\"]      = combineddf[\"FLOPs\"]      / (combineddf[\"CUDA Time\"]*10**9)\n",
    "\n",
    "\n",
    "### Get AI\n",
    "# L1\n",
    "combineddf[\"L1 AI\"]        = combineddf[\"FLOPs\"]      / combineddf[\"L1 Bytes\"]\n",
    "combineddf[\"FP32 L1 AI\"]   = combineddf[\"FP32 FLOPs\"] / combineddf[\"L1 Bytes\"]\n",
    "combineddf[\"FP16 L1 AI\"]   = combineddf[\"FP16 FLOPs\"] / combineddf[\"L1 Bytes\"]\n",
    "combineddf[\"TC L1 AI\"]     = combineddf[\"TC FLOPs\"]   / combineddf[\"L1 Bytes\"]\n",
    "# L2\n",
    "combineddf[\"L2 AI\"]        = combineddf[\"FLOPs\"]      / combineddf[\"L2 Bytes\"]\n",
    "combineddf[\"FP32 L2 AI\"]   = combineddf[\"FP32 FLOPs\"] / combineddf[\"L2 Bytes\"]\n",
    "combineddf[\"FP16 L2 AI\"]   = combineddf[\"FP16 FLOPs\"] / combineddf[\"L2 Bytes\"]\n",
    "combineddf[\"TC L2 AI\"]     = combineddf[\"TC FLOPs\"]   / combineddf[\"L2 Bytes\"]\n",
    "# DRAM\n",
    "combineddf[\"DRAM AI\"]      = combineddf[\"FLOPs\"]      / combineddf[\"DRAM Bytes\"]\n",
    "combineddf[\"FP32 DRAM AI\"] = combineddf[\"FP32 FLOPs\"] / combineddf[\"DRAM Bytes\"]\n",
    "combineddf[\"FP16 DRAM AI\"] = combineddf[\"FP16 FLOPs\"] / combineddf[\"DRAM Bytes\"]\n",
    "combineddf[\"TC DRAM AI\"]   = combineddf[\"TC FLOPs\"]   / combineddf[\"DRAM Bytes\"]\n",
    "\n",
    "combineddf.sort_values(by=combinedselectkeys).reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CUDA Time</th>\n",
       "      <th>Invocations</th>\n",
       "      <th>FP32 FLOPs</th>\n",
       "      <th>FP16 FLOPs</th>\n",
       "      <th>TC FLOPs</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>FP32 FLOPs Fraction</th>\n",
       "      <th>FP16 FLOPs Fraction</th>\n",
       "      <th>TC FLOPs Fraction</th>\n",
       "      <th>L1 Bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>FP16 L1 AI</th>\n",
       "      <th>TC L1 AI</th>\n",
       "      <th>L2 AI</th>\n",
       "      <th>FP32 L2 AI</th>\n",
       "      <th>FP16 L2 AI</th>\n",
       "      <th>TC L2 AI</th>\n",
       "      <th>DRAM AI</th>\n",
       "      <th>FP32 DRAM AI</th>\n",
       "      <th>FP16 DRAM AI</th>\n",
       "      <th>TC DRAM AI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <th>Cell</th>\n",
       "      <th>Input Shape</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Time Steps</th>\n",
       "      <th>Features</th>\n",
       "      <th>Hidden Size</th>\n",
       "      <th>Pass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">FP16</td>\n",
       "      <td rowspan=\"5\" valign=\"top\">lstm</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">128x32x32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">128</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">16</td>\n",
       "      <td>backward</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>1192</td>\n",
       "      <td>28344820.0</td>\n",
       "      <td>4792128.0</td>\n",
       "      <td>167772160.0</td>\n",
       "      <td>200909108.0</td>\n",
       "      <td>0.141083</td>\n",
       "      <td>0.023852</td>\n",
       "      <td>0.835065</td>\n",
       "      <td>70376322.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068093</td>\n",
       "      <td>2.383929</td>\n",
       "      <td>2.524666</td>\n",
       "      <td>0.356187</td>\n",
       "      <td>0.060219</td>\n",
       "      <td>2.108260</td>\n",
       "      <td>7.210730</td>\n",
       "      <td>1.017310</td>\n",
       "      <td>0.171992</td>\n",
       "      <td>6.021428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>forward</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>488</td>\n",
       "      <td>25505693.0</td>\n",
       "      <td>3674114.0</td>\n",
       "      <td>34603008.0</td>\n",
       "      <td>63782815.0</td>\n",
       "      <td>0.399883</td>\n",
       "      <td>0.057604</td>\n",
       "      <td>0.542513</td>\n",
       "      <td>48170302.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076273</td>\n",
       "      <td>0.718347</td>\n",
       "      <td>1.241076</td>\n",
       "      <td>0.496286</td>\n",
       "      <td>0.071490</td>\n",
       "      <td>0.673300</td>\n",
       "      <td>6.330072</td>\n",
       "      <td>2.531291</td>\n",
       "      <td>0.364634</td>\n",
       "      <td>3.434146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">256x32x32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">256</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">16</td>\n",
       "      <td>backward</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>1256</td>\n",
       "      <td>36827054.0</td>\n",
       "      <td>8739371.0</td>\n",
       "      <td>352321536.0</td>\n",
       "      <td>397887961.0</td>\n",
       "      <td>0.092556</td>\n",
       "      <td>0.021964</td>\n",
       "      <td>0.885479</td>\n",
       "      <td>127518082.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068534</td>\n",
       "      <td>2.762914</td>\n",
       "      <td>2.756015</td>\n",
       "      <td>0.255087</td>\n",
       "      <td>0.060534</td>\n",
       "      <td>2.440394</td>\n",
       "      <td>7.995908</td>\n",
       "      <td>0.740072</td>\n",
       "      <td>0.175625</td>\n",
       "      <td>7.080210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>forward</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>488</td>\n",
       "      <td>30687246.0</td>\n",
       "      <td>6031362.0</td>\n",
       "      <td>69206016.0</td>\n",
       "      <td>105924624.0</td>\n",
       "      <td>0.289708</td>\n",
       "      <td>0.056940</td>\n",
       "      <td>0.653352</td>\n",
       "      <td>88348812.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068268</td>\n",
       "      <td>0.783327</td>\n",
       "      <td>1.147712</td>\n",
       "      <td>0.332502</td>\n",
       "      <td>0.065351</td>\n",
       "      <td>0.749860</td>\n",
       "      <td>5.117737</td>\n",
       "      <td>1.482651</td>\n",
       "      <td>0.291405</td>\n",
       "      <td>3.343682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32x128x128</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>backward</td>\n",
       "      <td>0.020738</td>\n",
       "      <td>4648</td>\n",
       "      <td>31050434.0</td>\n",
       "      <td>5470663.0</td>\n",
       "      <td>470548480.0</td>\n",
       "      <td>507069577.0</td>\n",
       "      <td>0.061235</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.927976</td>\n",
       "      <td>93261752.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058659</td>\n",
       "      <td>5.045460</td>\n",
       "      <td>4.209550</td>\n",
       "      <td>0.257772</td>\n",
       "      <td>0.045416</td>\n",
       "      <td>3.906362</td>\n",
       "      <td>8.797738</td>\n",
       "      <td>0.538730</td>\n",
       "      <td>0.094917</td>\n",
       "      <td>8.164091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">FP32</td>\n",
       "      <td rowspan=\"5\" valign=\"top\">lstm</td>\n",
       "      <td>256x32x32</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>forward</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>489</td>\n",
       "      <td>88783264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88783264.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>112357580.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765648</td>\n",
       "      <td>0.765648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.716541</td>\n",
       "      <td>2.716541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">32x32x32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">16</td>\n",
       "      <td>backward</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>1194</td>\n",
       "      <td>51184182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51184182.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30037370.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.349313</td>\n",
       "      <td>1.349313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.708233</td>\n",
       "      <td>3.708233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>forward</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>489</td>\n",
       "      <td>32290274.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32290274.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21028750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.354980</td>\n",
       "      <td>1.354980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.381730</td>\n",
       "      <td>5.381730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">64x32x32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">64</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">16</td>\n",
       "      <td>backward</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>1194</td>\n",
       "      <td>79781799.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79781799.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51723310.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.289835</td>\n",
       "      <td>1.289835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.568048</td>\n",
       "      <td>3.568048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>forward</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>489</td>\n",
       "      <td>42909938.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42909938.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34106470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.126567</td>\n",
       "      <td>1.126567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.790547</td>\n",
       "      <td>4.790547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                CUDA Time  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                  \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward   0.005462   \n",
       "                                                                      forward    0.002112   \n",
       "               256x32x32   256        32         32       16          backward   0.005993   \n",
       "                                                                      forward    0.002082   \n",
       "               32x128x128  32         128        128      16          backward   0.020738   \n",
       "...                                                                                   ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward    0.002358   \n",
       "               32x32x32    32         32         32       16          backward   0.005308   \n",
       "                                                                      forward    0.002085   \n",
       "               64x32x32    64         32         32       16          backward   0.005512   \n",
       "                                                                      forward    0.002186   \n",
       "\n",
       "                                                                                Invocations  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                    \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward         1192   \n",
       "                                                                      forward           488   \n",
       "               256x32x32   256        32         32       16          backward         1256   \n",
       "                                                                      forward           488   \n",
       "               32x128x128  32         128        128      16          backward         4648   \n",
       "...                                                                                     ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward           489   \n",
       "               32x32x32    32         32         32       16          backward         1194   \n",
       "                                                                      forward           489   \n",
       "               64x32x32    64         32         32       16          backward         1194   \n",
       "                                                                      forward           489   \n",
       "\n",
       "                                                                                FP32 FLOPs  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                   \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward  28344820.0   \n",
       "                                                                      forward   25505693.0   \n",
       "               256x32x32   256        32         32       16          backward  36827054.0   \n",
       "                                                                      forward   30687246.0   \n",
       "               32x128x128  32         128        128      16          backward  31050434.0   \n",
       "...                                                                                    ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward   88783264.0   \n",
       "               32x32x32    32         32         32       16          backward  51184182.0   \n",
       "                                                                      forward   32290274.0   \n",
       "               64x32x32    64         32         32       16          backward  79781799.0   \n",
       "                                                                      forward   42909938.0   \n",
       "\n",
       "                                                                                FP16 FLOPs  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                   \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward   4792128.0   \n",
       "                                                                      forward    3674114.0   \n",
       "               256x32x32   256        32         32       16          backward   8739371.0   \n",
       "                                                                      forward    6031362.0   \n",
       "               32x128x128  32         128        128      16          backward   5470663.0   \n",
       "...                                                                                    ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward          0.0   \n",
       "               32x32x32    32         32         32       16          backward         0.0   \n",
       "                                                                      forward          0.0   \n",
       "               64x32x32    64         32         32       16          backward         0.0   \n",
       "                                                                      forward          0.0   \n",
       "\n",
       "                                                                                   TC FLOPs  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                    \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward  167772160.0   \n",
       "                                                                      forward    34603008.0   \n",
       "               256x32x32   256        32         32       16          backward  352321536.0   \n",
       "                                                                      forward    69206016.0   \n",
       "               32x128x128  32         128        128      16          backward  470548480.0   \n",
       "...                                                                                     ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward           0.0   \n",
       "               32x32x32    32         32         32       16          backward          0.0   \n",
       "                                                                      forward           0.0   \n",
       "               64x32x32    64         32         32       16          backward          0.0   \n",
       "                                                                      forward           0.0   \n",
       "\n",
       "                                                                                      FLOPs  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                    \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward  200909108.0   \n",
       "                                                                      forward    63782815.0   \n",
       "               256x32x32   256        32         32       16          backward  397887961.0   \n",
       "                                                                      forward   105924624.0   \n",
       "               32x128x128  32         128        128      16          backward  507069577.0   \n",
       "...                                                                                     ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward    88783264.0   \n",
       "               32x32x32    32         32         32       16          backward   51184182.0   \n",
       "                                                                      forward    32290274.0   \n",
       "               64x32x32    64         32         32       16          backward   79781799.0   \n",
       "                                                                      forward    42909938.0   \n",
       "\n",
       "                                                                                FP32 FLOPs Fraction  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                            \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward             0.141083   \n",
       "                                                                      forward              0.399883   \n",
       "               256x32x32   256        32         32       16          backward             0.092556   \n",
       "                                                                      forward              0.289708   \n",
       "               32x128x128  32         128        128      16          backward             0.061235   \n",
       "...                                                                                             ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward              1.000000   \n",
       "               32x32x32    32         32         32       16          backward             1.000000   \n",
       "                                                                      forward              1.000000   \n",
       "               64x32x32    64         32         32       16          backward             1.000000   \n",
       "                                                                      forward              1.000000   \n",
       "\n",
       "                                                                                FP16 FLOPs Fraction  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                            \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward             0.023852   \n",
       "                                                                      forward              0.057604   \n",
       "               256x32x32   256        32         32       16          backward             0.021964   \n",
       "                                                                      forward              0.056940   \n",
       "               32x128x128  32         128        128      16          backward             0.010789   \n",
       "...                                                                                             ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward              0.000000   \n",
       "               32x32x32    32         32         32       16          backward             0.000000   \n",
       "                                                                      forward              0.000000   \n",
       "               64x32x32    64         32         32       16          backward             0.000000   \n",
       "                                                                      forward              0.000000   \n",
       "\n",
       "                                                                                TC FLOPs Fraction  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                          \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward           0.835065   \n",
       "                                                                      forward            0.542513   \n",
       "               256x32x32   256        32         32       16          backward           0.885479   \n",
       "                                                                      forward            0.653352   \n",
       "               32x128x128  32         128        128      16          backward           0.927976   \n",
       "...                                                                                           ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward            0.000000   \n",
       "               32x32x32    32         32         32       16          backward           0.000000   \n",
       "                                                                      forward            0.000000   \n",
       "               64x32x32    64         32         32       16          backward           0.000000   \n",
       "                                                                      forward            0.000000   \n",
       "\n",
       "                                                                                   L1 Bytes  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                    \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward   70376322.0   \n",
       "                                                                      forward    48170302.0   \n",
       "               256x32x32   256        32         32       16          backward  127518082.0   \n",
       "                                                                      forward    88348812.0   \n",
       "               32x128x128  32         128        128      16          backward   93261752.0   \n",
       "...                                                                                     ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward   112357580.0   \n",
       "               32x32x32    32         32         32       16          backward   30037370.0   \n",
       "                                                                      forward    21028750.0   \n",
       "               64x32x32    64         32         32       16          backward   51723310.0   \n",
       "                                                                      forward    34106470.0   \n",
       "\n",
       "                                                                                ...  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass      ...   \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward  ...   \n",
       "                                                                      forward   ...   \n",
       "               256x32x32   256        32         32       16          backward  ...   \n",
       "                                                                      forward   ...   \n",
       "               32x128x128  32         128        128      16          backward  ...   \n",
       "...                                                                             ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward   ...   \n",
       "               32x32x32    32         32         32       16          backward  ...   \n",
       "                                                                      forward   ...   \n",
       "               64x32x32    64         32         32       16          backward  ...   \n",
       "                                                                      forward   ...   \n",
       "\n",
       "                                                                                FP16 L1 AI  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                   \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward    0.068093   \n",
       "                                                                      forward     0.076273   \n",
       "               256x32x32   256        32         32       16          backward    0.068534   \n",
       "                                                                      forward     0.068268   \n",
       "               32x128x128  32         128        128      16          backward    0.058659   \n",
       "...                                                                                    ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward     0.000000   \n",
       "               32x32x32    32         32         32       16          backward    0.000000   \n",
       "                                                                      forward     0.000000   \n",
       "               64x32x32    64         32         32       16          backward    0.000000   \n",
       "                                                                      forward     0.000000   \n",
       "\n",
       "                                                                                TC L1 AI  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                 \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward  2.383929   \n",
       "                                                                      forward   0.718347   \n",
       "               256x32x32   256        32         32       16          backward  2.762914   \n",
       "                                                                      forward   0.783327   \n",
       "               32x128x128  32         128        128      16          backward  5.045460   \n",
       "...                                                                                  ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward   0.000000   \n",
       "               32x32x32    32         32         32       16          backward  0.000000   \n",
       "                                                                      forward   0.000000   \n",
       "               64x32x32    64         32         32       16          backward  0.000000   \n",
       "                                                                      forward   0.000000   \n",
       "\n",
       "                                                                                   L2 AI  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                 \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward  2.524666   \n",
       "                                                                      forward   1.241076   \n",
       "               256x32x32   256        32         32       16          backward  2.756015   \n",
       "                                                                      forward   1.147712   \n",
       "               32x128x128  32         128        128      16          backward  4.209550   \n",
       "...                                                                                  ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward   0.765648   \n",
       "               32x32x32    32         32         32       16          backward  1.349313   \n",
       "                                                                      forward   1.354980   \n",
       "               64x32x32    64         32         32       16          backward  1.289835   \n",
       "                                                                      forward   1.126567   \n",
       "\n",
       "                                                                                FP32 L2 AI  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                   \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward    0.356187   \n",
       "                                                                      forward     0.496286   \n",
       "               256x32x32   256        32         32       16          backward    0.255087   \n",
       "                                                                      forward     0.332502   \n",
       "               32x128x128  32         128        128      16          backward    0.257772   \n",
       "...                                                                                    ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward     0.765648   \n",
       "               32x32x32    32         32         32       16          backward    1.349313   \n",
       "                                                                      forward     1.354980   \n",
       "               64x32x32    64         32         32       16          backward    1.289835   \n",
       "                                                                      forward     1.126567   \n",
       "\n",
       "                                                                                FP16 L2 AI  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                   \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward    0.060219   \n",
       "                                                                      forward     0.071490   \n",
       "               256x32x32   256        32         32       16          backward    0.060534   \n",
       "                                                                      forward     0.065351   \n",
       "               32x128x128  32         128        128      16          backward    0.045416   \n",
       "...                                                                                    ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward     0.000000   \n",
       "               32x32x32    32         32         32       16          backward    0.000000   \n",
       "                                                                      forward     0.000000   \n",
       "               64x32x32    64         32         32       16          backward    0.000000   \n",
       "                                                                      forward     0.000000   \n",
       "\n",
       "                                                                                TC L2 AI  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                 \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward  2.108260   \n",
       "                                                                      forward   0.673300   \n",
       "               256x32x32   256        32         32       16          backward  2.440394   \n",
       "                                                                      forward   0.749860   \n",
       "               32x128x128  32         128        128      16          backward  3.906362   \n",
       "...                                                                                  ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward   0.000000   \n",
       "               32x32x32    32         32         32       16          backward  0.000000   \n",
       "                                                                      forward   0.000000   \n",
       "               64x32x32    64         32         32       16          backward  0.000000   \n",
       "                                                                      forward   0.000000   \n",
       "\n",
       "                                                                                 DRAM AI  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                 \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward  7.210730   \n",
       "                                                                      forward   6.330072   \n",
       "               256x32x32   256        32         32       16          backward  7.995908   \n",
       "                                                                      forward   5.117737   \n",
       "               32x128x128  32         128        128      16          backward  8.797738   \n",
       "...                                                                                  ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward   2.716541   \n",
       "               32x32x32    32         32         32       16          backward  3.708233   \n",
       "                                                                      forward   5.381730   \n",
       "               64x32x32    64         32         32       16          backward  3.568048   \n",
       "                                                                      forward   4.790547   \n",
       "\n",
       "                                                                                FP32 DRAM AI  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                     \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward      1.017310   \n",
       "                                                                      forward       2.531291   \n",
       "               256x32x32   256        32         32       16          backward      0.740072   \n",
       "                                                                      forward       1.482651   \n",
       "               32x128x128  32         128        128      16          backward      0.538730   \n",
       "...                                                                                      ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward       2.716541   \n",
       "               32x32x32    32         32         32       16          backward      3.708233   \n",
       "                                                                      forward       5.381730   \n",
       "               64x32x32    64         32         32       16          backward      3.568048   \n",
       "                                                                      forward       4.790547   \n",
       "\n",
       "                                                                                FP16 DRAM AI  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                     \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward      0.171992   \n",
       "                                                                      forward       0.364634   \n",
       "               256x32x32   256        32         32       16          backward      0.175625   \n",
       "                                                                      forward       0.291405   \n",
       "               32x128x128  32         128        128      16          backward      0.094917   \n",
       "...                                                                                      ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward       0.000000   \n",
       "               32x32x32    32         32         32       16          backward      0.000000   \n",
       "                                                                      forward       0.000000   \n",
       "               64x32x32    64         32         32       16          backward      0.000000   \n",
       "                                                                      forward       0.000000   \n",
       "\n",
       "                                                                                TC DRAM AI  \n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                  \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward    6.021428  \n",
       "                                                                      forward     3.434146  \n",
       "               256x32x32   256        32         32       16          backward    7.080210  \n",
       "                                                                      forward     3.343682  \n",
       "               32x128x128  32         128        128      16          backward    8.164091  \n",
       "...                                                                                    ...  \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward     0.000000  \n",
       "               32x32x32    32         32         32       16          backward    0.000000  \n",
       "                                                                      forward     0.000000  \n",
       "               64x32x32    64         32         32       16          backward    0.000000  \n",
       "                                                                      forward     0.000000  \n",
       "\n",
       "[86 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(combineddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>L2 AI</th>\n",
       "      <th>L1 AI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <th>Cell</th>\n",
       "      <th>Input Shape</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Time Steps</th>\n",
       "      <th>Features</th>\n",
       "      <th>Hidden Size</th>\n",
       "      <th>Pass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">FP16</td>\n",
       "      <td rowspan=\"5\" valign=\"top\">lstm</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">128x32x32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">128</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">16</td>\n",
       "      <td>backward</td>\n",
       "      <td>2.524666</td>\n",
       "      <td>2.854783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>forward</td>\n",
       "      <td>1.241076</td>\n",
       "      <td>1.324111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">256x32x32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">256</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">16</td>\n",
       "      <td>backward</td>\n",
       "      <td>2.756015</td>\n",
       "      <td>3.120247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>forward</td>\n",
       "      <td>1.147712</td>\n",
       "      <td>1.198937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32x128x128</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>backward</td>\n",
       "      <td>4.209550</td>\n",
       "      <td>5.437058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">FP32</td>\n",
       "      <td rowspan=\"5\" valign=\"top\">lstm</td>\n",
       "      <td>256x32x32</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>forward</td>\n",
       "      <td>0.765648</td>\n",
       "      <td>0.790185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">32x32x32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">16</td>\n",
       "      <td>backward</td>\n",
       "      <td>1.349313</td>\n",
       "      <td>1.704017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>forward</td>\n",
       "      <td>1.354980</td>\n",
       "      <td>1.535530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">64x32x32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">64</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">32</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">16</td>\n",
       "      <td>backward</td>\n",
       "      <td>1.289835</td>\n",
       "      <td>1.542473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>forward</td>\n",
       "      <td>1.126567</td>\n",
       "      <td>1.258117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                   L2 AI  \\\n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                 \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward  2.524666   \n",
       "                                                                      forward   1.241076   \n",
       "               256x32x32   256        32         32       16          backward  2.756015   \n",
       "                                                                      forward   1.147712   \n",
       "               32x128x128  32         128        128      16          backward  4.209550   \n",
       "...                                                                                  ...   \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward   0.765648   \n",
       "               32x32x32    32         32         32       16          backward  1.349313   \n",
       "                                                                      forward   1.354980   \n",
       "               64x32x32    64         32         32       16          backward  1.289835   \n",
       "                                                                      forward   1.126567   \n",
       "\n",
       "                                                                                   L1 AI  \n",
       "Precision Cell Input Shape Batch Size Time Steps Features Hidden Size Pass                \n",
       "FP16      lstm 128x32x32   128        32         32       16          backward  2.854783  \n",
       "                                                                      forward   1.324111  \n",
       "               256x32x32   256        32         32       16          backward  3.120247  \n",
       "                                                                      forward   1.198937  \n",
       "               32x128x128  32         128        128      16          backward  5.437058  \n",
       "...                                                                                  ...  \n",
       "FP32      lstm 256x32x32   256        32         32       16          forward   0.790185  \n",
       "               32x32x32    32         32         32       16          backward  1.704017  \n",
       "                                                                      forward   1.535530  \n",
       "               64x32x32    64         32         32       16          backward  1.542473  \n",
       "                                                                      forward   1.258117  \n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(combineddf[[\"L2 AI\", \"L1 AI\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiledf.to_csv(os.path.join(outputdir,\"full_profile.csv\"))\n",
    "combineddf.to_csv(os.path.join(outputdir,\"combined_profile.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
