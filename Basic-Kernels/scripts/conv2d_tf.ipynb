{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir='.'\n",
    "# os.mkdir(dir)\n",
    "# %rm <where BasicKernels/scripts is>/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d-tf1-xla.sh\n",
      "conv2d-tf1-noxla.sh\n",
      "conv2d-tf2-xla.sh\n",
      "conv2d-tf2-noxla.sh\n"
     ]
    }
   ],
   "source": [
    "xlas=['xla','noxla']\n",
    "versions=['1','2']\n",
    "\n",
    "for version in versions:\n",
    "    for xla in xlas:\n",
    "        fn='conv2d-tf'+version+'-'+xla+'.sh'\n",
    "        print(fn)\n",
    "\n",
    "        with open(os.path.join(dir,fn),'w') as f:\n",
    "            f.write('''#!/bin/bash\n",
    "#SBATCH -J {fn}\\n'''.format(fn=fn.split('.')[0]))\n",
    "            f.write('''#SBATCH -C gpu\n",
    "#SBATCH --gres=gpu:8\n",
    "#SBATCH --exclusive\n",
    "#SBATCH -q special\n",
    "#SBATCH -A m1759\n",
    "#SBATCH -t 04:00:00\n",
    "\n",
    "#activate env\n",
    "module load tensorflow/{mod}\n",
    "export PROFILER='cupy'\n",
    "\\n'''.format(mod='gpu-2.2.0-py37' if version=='2' else 'gpu-1.15.0-py37'))\n",
    "\n",
    "            f.write('''#enalbe XLA or not, 'xla' or 'noxla'\n",
    "export enable_xla='{xla}'\n",
    "\n",
    "#export TF_XLA_FLAGS=\"--tf_xla_auto_jit=2\"\n",
    "export XLA_FLAGS=--xla_gpu_cuda_data_dir=${{CUDA_HOME}}\n",
    "export CUDA_DIR=${{CUDA_HOME}}\n",
    "\\n'''.format(xla=xla))\n",
    "            \n",
    "            f.write('''#rankspernode\n",
    "rankspernode=1\n",
    "\n",
    "#openmp  \n",
    "export OMP_NUM_THREADS=$(( 40 / ${rankspernode} ))\n",
    "export OMP_PLACES=threads\n",
    "export OMP_PROC_BIND=spread\n",
    "sruncmd=\"srun -N ${SLURM_NNODES} -n $(( ${SLURM_NNODES} * ${rankspernode} )) --cpu_bind=cores\"\n",
    "\\n''')\n",
    "\n",
    "            f.write('''#create run dir\n",
    "run_dir=$PWD/tf_cnn_kernels_nsight/conv2d-tf{version}-{xla}/$SLURM_JOBID/\n",
    "mkdir -p ${{run_dir}}\n",
    "\n",
    "#copy relevant files\n",
    "script_dir=../python\n",
    "script=\"conv2d_tf{version}.py\"\n",
    "cp $script_dir/$script $run_dir/\n",
    "\n",
    "#step in\n",
    "cd $run_dir\n",
    "\\n'''.format(version=version,xla=xla))\n",
    "        \n",
    "            if version == '1':\n",
    "                f.write('''if [ $enable_xla == \"xla\" ];then\n",
    "    sed -i 's/allow_soft_placement=False/allow_soft_placement=True/g' $script\n",
    "fi\n",
    "\\n''')\n",
    "\n",
    "            f.write('''#net_params\n",
    "net_params=\"ResNet50-2,112x112x64,3x3x64x64,1,16 ResNet50-2,112x112x64,3x3x64x64,2,16 ResNet50-2,112x112x64,3x3x64x64,3,16 \"\n",
    "net_params+=\"ResNet50-2,112x112x64,3x3x64x64,2,32 ResNet50-2,112x112x64,3x3x64x64,2,64 \"\n",
    "net_params+=\"ResNet50-2,112x112x64,7x7x64x64,2,16 ResNet50-2,112x112x64,9x9x64x64,2,16 \"\n",
    "net_params+=\"ResNet50-2,112x112x64,3x3x64x128,2,16 ResNet50-2,112x112x64,3x3x64x256,2,16 ResNet50-2,112x112x64,3x3x64x512,2,16 \"\n",
    "\n",
    "#list of metrics\n",
    "#metrics=\"sm__cycles_elapsed.avg \"\n",
    "metrics=\"sm__cycles_elapsed.avg.per_second,\\\\\n",
    "sm__cycles_elapsed.avg,\\\\\n",
    "sm__inst_executed_pipe_tensor.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_fadd_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_ffma_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_fmul_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_hadd_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_hfma_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_hmul_pred_on.sum,\\\\\n",
    "dram__bytes.sum,\\\\\n",
    "lts__t_bytes.sum,\\\\\n",
    "l1tex__t_bytes.sum \"\n",
    "\n",
    "#export TF_XLA_FLAGS=\"--tf_xla_auto_jit=2\"\n",
    "#export XLA_FLAGS=\"--xla_dump_to=$run_dir\" \n",
    "#data_formats=\"NHWC NCHW \"\n",
    "precs=\"16 32\"\n",
    "data_formats=\"NHWC \"\n",
    "\n",
    "num_warmup=5\n",
    "num_iter=1\n",
    "\n",
    "for prec in $precs; do\n",
    "    for data_format in $data_formats; do\n",
    "\n",
    "        #iterate over input tuples\n",
    "        for net_param in ${net_params}; do \n",
    "            tmp_param=(${net_param//,/ })\n",
    "            name=${tmp_param[0]}\n",
    "            input_tensor_shape=${tmp_param[1]//x/ }\n",
    "            kernel_shape=${tmp_param[2]//x/ }\n",
    "            stride=${tmp_param[3]}\n",
    "            batch_size=${tmp_param[4]}\n",
    "\\n''')\n",
    "\n",
    "            f.write('''            outputstr1=tf{version}.name_${{name}}.batch_${{tmp_param[4]}}.input_${{tmp_param[1]}}\\n'''.format(version=version))\n",
    "            f.write('''            outputstr2=kernel_${tmp_param[2]}.stride_${stride}.data_${data_format}.fp${prec}\n",
    "\n",
    "            #iterate over FW BW\n",
    "            for ctype in calibrate forward backward; do\n",
    "\n",
    "                #profile string\n",
    "                profilestring=\"/usr/common/software/cuda/11.0.167/bin/nv-nsight-cu-cli \\\\\n",
    "                --profile-from-start off --metrics ${metrics} --kernel-base demangled -o \\\\\n",
    "                ${outputstr1}.${outputstr2}.pass_${ctype}.${enable_xla}\"\n",
    "\n",
    "                if [ $enable_xla == \"xla\" ];then\n",
    "                    ${sruncmd} ${profilestring} $(which python) -u ./$script \\\\\n",
    "                        --dtype float${prec} \\\\\n",
    "                        --data_format ${data_format} \\\\\n",
    "                        --input_tensor_shape ${batch_size} ${input_tensor_shape} \\\\\n",
    "                        --kernel_shape ${kernel_shape} \\\\\n",
    "                        --stride ${stride} \\\\\n",
    "                        --num_warmups ${num_warmup} \\\\\n",
    "                        --num_iterations ${num_iter} \\\\\n",
    "                        --enable_xla \\\\\n",
    "                        --compute_type ${ctype}\n",
    "                else\n",
    "                    ${sruncmd} ${profilestring} $(which python) -u ./$script \\\\\n",
    "                        --dtype float${prec} \\\\\n",
    "                        --data_format ${data_format} \\\\\n",
    "                        --input_tensor_shape ${batch_size} ${input_tensor_shape} \\\\\n",
    "                        --kernel_shape ${kernel_shape} \\\\\n",
    "                        --stride ${stride} \\\\\n",
    "                        --num_warmups ${num_warmup} \\\\\n",
    "                        --num_iterations ${num_iter} \\\\\n",
    "                        --compute_type ${ctype}\n",
    "                fi\n",
    "\n",
    "            done\n",
    "        done\n",
    "\n",
    "    done\n",
    "done\\n''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
