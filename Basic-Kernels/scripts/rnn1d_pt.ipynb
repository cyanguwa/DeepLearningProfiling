{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir='/global/cfs/cdirs/nstaff/cjyang/study/Yunsong/tf-perf-kernels/scripts/pygen'\n",
    "# os.mkdir(dir)\n",
    "# %rm /global/cfs/cdirs/nstaff/cjyang/study/Yunsong/tf-perf-kernels/scripts/pygen/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn1d-pt.sh\n"
     ]
    }
   ],
   "source": [
    "# no xla, no version difference\n",
    "fn='rnn1d-pt.sh'\n",
    "print(fn)\n",
    "\n",
    "with open(os.path.join(dir,fn),'w') as f:\n",
    "    f.write('''#!/bin/bash\n",
    "#SBATCH -J {fn}\\n'''.format(fn=fn.split('.')[0]))\n",
    "    f.write('''#SBATCH -C gpu\n",
    "#SBATCH --gres=gpu:1\n",
    "##SBATCH --exclusive\n",
    "#SBATCH -t 04:00:00\n",
    "\n",
    "#activate env\n",
    "conda activate /global/cfs/cdirs/m1759/charlene/condaenvs/py3.7pt1.5cuda10.2.89\n",
    "export PROFILER='cupy'\n",
    "\\n''')\n",
    "            \n",
    "    f.write('''#rankspernode\n",
    "rankspernode=1\n",
    "\n",
    "#openmp  \n",
    "export OMP_NUM_THREADS=$(( 40 / ${rankspernode} ))\n",
    "export OMP_PLACES=threads\n",
    "export OMP_PROC_BIND=spread\n",
    "sruncmd=\"srun -N ${SLURM_NNODES} -n $(( ${SLURM_NNODES} * ${rankspernode} )) --cpu_bind=cores\"\n",
    "\\n''')\n",
    "\n",
    "    f.write('''#create run dir\n",
    "run_dir=$SCRATCH/tf_cnn_kernels_nsight/Ker-rnn1d-pt-$SLURM_JOBID/\n",
    "mkdir -p ${run_dir}\n",
    "\n",
    "#copy relevant files\n",
    "script_dir=/where BasicKernels is/\n",
    "script=\"rnn1d_pt.py\"\n",
    "cp ${script_dir}/python/$script ${run_dir}/\n",
    "cp $0 ${run_dir}/rnn1d-pt.sh\n",
    "\n",
    "#step in\n",
    "cd ${run_dir}\n",
    "\\n''')\n",
    "\n",
    "    f.write('''#net_params\n",
    "net_params=\"64x64x64,64,16,3 \"\n",
    "#net_params=\"64x64x1,64,16,3 128x64x1,64,16,3 256x64x1,64,16,3 \\\\\n",
    "#64x128x1,128,16,3 128x256x1,256,16,3 256x64x1,64,4,3 \\\\\n",
    "#64x64x1,64,16,5 64x64x1,64,16,7 256x256x1,256,16,7 \"\n",
    "#net_params=\"64x16x64,32 128x16x64,32 256x16x64,32 \"\n",
    "#net_params+=\"64x64x64,32 64x16x128,32 64x16x256,32 \"\n",
    "#net_params+=\"64x16x64,64 64x16x64,128 64x16x64,256 \"\n",
    "\n",
    "#list of metrics\n",
    "#metrics=\"sm__cycles_elapsed.avg \"\n",
    "metrics=\"sm__cycles_elapsed.avg.per_second,\\\\\n",
    "sm__cycles_elapsed.avg,\\\\\n",
    "sm__inst_executed_pipe_tensor.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_fadd_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_ffma_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_fmul_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_hadd_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_hfma_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_hmul_pred_on.sum,\\\\\n",
    "dram__bytes.sum,\\\\\n",
    "lts__t_bytes.sum,\\\\\n",
    "l1tex__t_bytes.sum \"\n",
    "\n",
    "#export TF_XLA_FLAGS=\"--tf_xla_auto_jit=2\"\n",
    "#export XLA_FLAGS=\"--xla_dump_to=$run_dir\" \n",
    "\n",
    "cells=\"RNN LSTM GRU \"\n",
    "precs=\"16 32\"\n",
    "#cells=\"RNN \"\n",
    "#precs=\"16 \"\n",
    "\n",
    "num_warmup=5\n",
    "num_iter=1\n",
    "\n",
    "for prec in $precs; do\n",
    "    for cell in $cells; do\n",
    "    \n",
    "            #iterate over input tuples\n",
    "            for net_param in ${net_params}; do \n",
    "                tmp_param=(${net_param//,/ })\n",
    "                input_tensor_shape=${tmp_param[0]//x/ }                 \n",
    "                input_size=${tmp_param[1]}\n",
    "                hidden_size=${tmp_param[2]}\n",
    "                nneu=${tmp_param[3]}\n",
    "\n",
    "                #iterate over FW BW\n",
    "                for ctype in calibrate forward backward; do\n",
    "                    \n",
    "                    outputstr=pt.fp_${prec}.celltype_${cell}.input_${tmp_param[0]}.nneu_${nneu}.pass_${ctype}\n",
    "                    \n",
    "                    #profile string\n",
    "                    profilestring=\"/usr/common/software/cuda/11.0.167/bin/nv-nsight-cu-cli \\\\\n",
    "                    --profile-from-start off --metrics ${metrics} --csv --kernel-base demangled\"\n",
    "\n",
    "                    ${sruncmd} ${profilestring} $(which python) -u ./$script \\\\\n",
    "                        --input_tensor_shape $input_tensor_shape \\\\\n",
    "                        --cell_type $cell \\\\\n",
    "                        --input_size $input_size \\\\\n",
    "                        --hidden_size $hidden_size \\\\\n",
    "                        --num_layers $nneu \\\\\n",
    "                        --dtype float${prec} \\\\\n",
    "                        --num_iterations $num_iter \\\\\n",
    "                        --num_warmups $num_warmup \\\\\n",
    "                        --compute_type ${ctype} 2>&1 > out.${outputstr}\n",
    "                done\n",
    "            done\n",
    "    done\n",
    "done\\n''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
