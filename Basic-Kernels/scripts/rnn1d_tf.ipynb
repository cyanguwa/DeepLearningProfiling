{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir='.'\n",
    "# os.mkdir(dir)\n",
    "# %rm <where BasicKernels/scripts is>/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn1d-tf1-noxla.sh\n",
      "rnn1d-tf2-xla.sh\n",
      "rnn1d-tf2-noxla.sh\n"
     ]
    }
   ],
   "source": [
    "## versions=['1','2']\n",
    "versions=['1','2']\n",
    "\n",
    "for version in versions:\n",
    "    if version == '1':\n",
    "        xlas=['noxla']\n",
    "    else:\n",
    "        xlas=['xla','noxla']\n",
    "    for xla in xlas:\n",
    "        fn='rnn1d-tf'+version+'-'+xla+'.sh'\n",
    "        print(fn)\n",
    "\n",
    "        with open(os.path.join(dir,fn),'w') as f:\n",
    "            f.write('''#!/bin/bash\n",
    "#SBATCH -J {fn}\\n'''.format(fn=fn.split('.')[0]))\n",
    "            f.write('''#SBATCH -C gpu\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --exclusive\n",
    "#SBATCH -q special\n",
    "#SBATCH -A m1759\n",
    "#SBATCH -t 4:00:00\n",
    "\n",
    "#activate env\n",
    "module load tensorflow/{mod}\n",
    "export PROFILER='cupy'\n",
    "\\n'''.format(mod='gpu-2.2.0-py37' if version=='2' else 'gpu-1.15.0-py37'))\n",
    "\n",
    "            f.write('''#enalbe XLA or not, 'xla' or 'noxla'\n",
    "export enable_xla='{xla}'\n",
    "\n",
    "export XLA_FLAGS=--xla_gpu_cuda_data_dir=${{CUDA_HOME}}\n",
    "export CUDA_DIR=${{CUDA_HOME}}\n",
    "\\n'''.format(xla=xla))\n",
    "            \n",
    "            f.write('''#rankspernode\n",
    "rankspernode=1\n",
    "\n",
    "#openmp  \n",
    "export OMP_NUM_THREADS=$(( 40 / ${rankspernode} ))\n",
    "export OMP_PLACES=threads\n",
    "export OMP_PROC_BIND=spread\n",
    "sruncmd=\"srun -N ${SLURM_NNODES} -n $(( ${SLURM_NNODES} * ${rankspernode} )) --cpu_bind=cores\"\n",
    "\\n''')\n",
    "\n",
    "            f.write('''#create run dir\n",
    "run_dir=$PWD/tf_cnn_kernels_nsight/rnn1d-tf{version}-{xla}/$SLURM_JOBID/\n",
    "mkdir -p ${{run_dir}}\n",
    "\n",
    "#copy relevant files\n",
    "script_dir=../python\n",
    "script=\"rnn1d_tf{version}.py\"\n",
    "cp $script_dir/$script $run_dir/\n",
    "\n",
    "#step in\n",
    "cd ${{run_dir}}\n",
    "\\n'''.format(version=version,xla=xla))\n",
    "        \n",
    "            if version == '1':\n",
    "                f.write('''if [ $enable_xla == \"xla\" ];then\n",
    "    sed -i 's/allow_soft_placement=False/allow_soft_placement=True/g' $script\n",
    "fi\n",
    "\\n''')\n",
    "\n",
    "            f.write('''#net_params\n",
    "net_params=\"16,16,32,16 32,16,32,16, 64,16,32,16 128,16,32,16 \"\n",
    "net_params+=\"16,32,32,16 16,64,32,16 16,128,32,16 \"\n",
    "net_params+=\"16,16,64,16 16,16,128,16 \"\n",
    "net_params+=\"16,16,32,32 16,16,32,64 16,16,32,128 \"\n",
    "\n",
    "#list of metrics\n",
    "#metrics=\"sm__cycles_elapsed.avg \"\n",
    "metrics=\"sm__cycles_elapsed.avg.per_second,\\\\\n",
    "sm__cycles_elapsed.avg,\\\\\n",
    "sm__inst_executed_pipe_tensor.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_fadd_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_ffma_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_fmul_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_hadd_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_hfma_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_hmul_pred_on.sum,\\\\\n",
    "dram__bytes.sum,\\\\\n",
    "lts__t_bytes.sum,\\\\\n",
    "l1tex__t_bytes.sum \"\n",
    "\n",
    "#export TF_XLA_FLAGS=\"--tf_xla_auto_jit=2\"\n",
    "#export XLA_FLAGS=\"--xla_dump_to=$run_dir\"\n",
    "\n",
    "cells=\"lstm\"\n",
    "precs=\"16 32\"\n",
    "\n",
    "num_warmup=5\n",
    "num_iter=1\n",
    "\n",
    "for prec in $precs; do\n",
    "    for cell in $cells; do\n",
    "        for net_param in ${net_params}; do\n",
    "            tmp_param=(${net_param//,/ })\n",
    "            batch=${tmp_param[0]}\n",
    "            time=${tmp_param[1]}\n",
    "            feature=${tmp_param[2]}\n",
    "            h_size=${tmp_param[3]}\n",
    "            input_tensor_shape=$batch\" \"$time\" \"$feature\n",
    "            echo $input_tensor_shape\n",
    "\\n''')\n",
    "                \n",
    "            f.write('''            outputstr=tf{version}.fp_${{prec}}.celltype_${{cell}}.input_${{batch}}x${{time}}x${{feature}}.nneu_${{h_size}}\\n'''.format(version=version))\n",
    "            f.write('''            #iterate over FW BW\n",
    "            for ctype in calibrate forward backward; do\n",
    "\n",
    "                #profile string\n",
    "                profilestring=\"/usr/common/software/cuda/11.0.167/bin/nv-nsight-cu-cli \\\\\n",
    "                --profile-from-start off --metrics ${metrics} --kernel-base demangled -o \\\\\n",
    "                ${outputstr}.pass_${ctype}.${enable_xla}\"\n",
    "\n",
    "                if [ $enable_xla == \"xla\" ];then\n",
    "                    ${sruncmd} ${profilestring} $(which python) -u ./$script \\\\\n",
    "                        --input_tensor_shape ${input_tensor_shape} \\\\\n",
    "                        --cell_type ${cell} \\\\\n",
    "                        --n_neurons ${h_size} \\\\\n",
    "                        --dtype float${prec} \\\\\n",
    "                        --num_iterations ${num_iter} \\\\\n",
    "                        --num_warmups ${num_warmup} \\\\\n",
    "                        --enable_xla \\\\\n",
    "                        --compute_type ${ctype}\n",
    "                else\n",
    "                    ${sruncmd} ${profilestring} $(which python) -u ./$script \\\\\n",
    "                        --input_tensor_shape ${input_tensor_shape} \\\\\n",
    "                        --cell_type ${cell} \\\\\n",
    "                        --n_neurons ${h_size} \\\\\n",
    "                        --dtype float${prec} \\\\\n",
    "                        --num_iterations ${num_iter} \\\\\n",
    "                        --num_warmups ${num_warmup} \\\\\n",
    "                        --compute_type ${ctype}\n",
    "                fi\n",
    "            done\n",
    "        done\n",
    "    done\n",
    "done\\n''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
