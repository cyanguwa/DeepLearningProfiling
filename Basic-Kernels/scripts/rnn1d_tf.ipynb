{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir='<where BasicKernels/scripts is>'\n",
    "# os.mkdir(dir)\n",
    "# %rm <where BasicKernels/scripts is>/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn1d-tf1-noxla.sh\n",
      "rnn1d-tf2-xla.sh\n",
      "rnn1d-tf2-noxla.sh\n"
     ]
    }
   ],
   "source": [
    "versions=['1','2']\n",
    "\n",
    "for version in versions:\n",
    "    if version == '1':\n",
    "        xlas=['noxla']\n",
    "    else:\n",
    "        xlas=['xla','noxla']\n",
    "    for xla in xlas:\n",
    "        fn='rnn1d-tf'+version+'-'+xla+'.sh'\n",
    "        print(fn)\n",
    "\n",
    "        with open(os.path.join(dir,fn),'w') as f:\n",
    "            f.write('''#!/bin/bash\n",
    "#SBATCH -J {fn}\\n'''.format(fn=fn.split('.')[0]))\n",
    "            f.write('''#SBATCH -C gpu\n",
    "#SBATCH --gres=gpu:1\n",
    "##SBATCH --exclusive\n",
    "#SBATCH -t 04:00:00\n",
    "\n",
    "#activate env\n",
    "module load tensorflow/{mod}\n",
    "export PROFILER='cupy'\n",
    "\\n'''.format(mod='gpu-2.2.0-py37' if version=='2' else 'gpu-1.15.0-py37'))\n",
    "\n",
    "            f.write('''#enalbe XLA or not, 'xla' or 'noxla'\n",
    "export enable_xla='{xla}'\n",
    "\n",
    "export XLA_FLAGS=--xla_gpu_cuda_data_dir=${{CUDA_HOME}}\n",
    "export CUDA_DIR=${{CUDA_HOME}}\n",
    "\\n'''.format(xla=xla))\n",
    "            \n",
    "            f.write('''#rankspernode\n",
    "rankspernode=1\n",
    "\n",
    "#openmp  \n",
    "export OMP_NUM_THREADS=$(( 40 / ${rankspernode} ))\n",
    "export OMP_PLACES=threads\n",
    "export OMP_PROC_BIND=spread\n",
    "sruncmd=\"srun -N ${SLURM_NNODES} -n $(( ${SLURM_NNODES} * ${rankspernode} )) --cpu_bind=cores\"\n",
    "\\n''')\n",
    "\n",
    "            f.write('''#create run dir\n",
    "run_dir=$SCRATCH/tf_cnn_kernels_nsight/Ker-rnn1d-tf{version}-{xla}-$SLURM_JOBID/\n",
    "mkdir -p ${{run_dir}}\n",
    "\n",
    "#copy relevant files\n",
    "script_dir=<where BasicKernels is>\n",
    "script=\"rnn1d_tf{version}.py\"\n",
    "cp ${{script_dir}}/python/$script ${{run_dir}}/\n",
    "cp $0 ${{run_dir}}/rnn1d-tf{version}-$enable_xla.sh\n",
    "\n",
    "#step in\n",
    "cd ${{run_dir}}\n",
    "\\n'''.format(version=version,xla=xla))\n",
    "        \n",
    "            if version == '1':\n",
    "                f.write('''if [ $enable_xla == \"xla\" ];then\n",
    "    sed -i 's/allow_soft_placement=False/allow_soft_placement=True/g' $script\n",
    "fi\n",
    "\\n''')\n",
    "\n",
    "            f.write('''#net_params\n",
    "net_params=\"64x64x16,3 128x64x16,3 256x64x16,3 \\\\\n",
    "64x128x16,3 128x256x16,3 256x64x4,3 \\\\\n",
    "64x64x16,5 64x64x16,7 256x256x16,7 \"\n",
    "#net_params=\"1x2x32,3\"\n",
    "#net_params=\"64x16x64,32 128x16x64,32 256x16x64,32 \"\n",
    "#net_params+=\"64x64x64,32 64x16x128,32 64x16x256,32 \"\n",
    "#net_params+=\"64x16x64,64 64x16x64,128 64x16x64,256 \"\n",
    "\n",
    "#list of metrics\n",
    "#metrics=\"sm__cycles_elapsed.avg \"\n",
    "metrics=\"sm__cycles_elapsed.avg.per_second,\\\\\n",
    "sm__cycles_elapsed.avg,\\\\\n",
    "sm__inst_executed_pipe_tensor.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_fadd_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_ffma_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_fmul_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_hadd_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_hfma_pred_on.sum,\\\\\n",
    "sm__sass_thread_inst_executed_op_hmul_pred_on.sum,\\\\\n",
    "dram__bytes.sum,\\\\\n",
    "lts__t_bytes.sum,\\\\\n",
    "l1tex__t_bytes.sum \"\n",
    "\n",
    "#export TF_XLA_FLAGS=\"--tf_xla_auto_jit=2\"\n",
    "#export XLA_FLAGS=\"--xla_dump_to=$run_dir\"\n",
    "\n",
    "cells=\"rnn lstm gru \"\n",
    "precs=\"16 32\"\n",
    "#cells=\"rnn \"\n",
    "#precs=\"16 \"\n",
    "\n",
    "num_warmup=5\n",
    "num_iter=1\n",
    "\n",
    "for prec in $precs; do\n",
    "    for cell in $cells; do\n",
    "    \n",
    "            #iterate over input tuples\n",
    "            for net_param in ${net_params}; do \n",
    "                tmp_param=(${net_param//,/ })\n",
    "                input_tensor_shape=${tmp_param[0]//x/ }\n",
    "                nneu=${tmp_param[1]}\n",
    "\\n''')\n",
    "                \n",
    "            f.write('''                outputstr=tf{version}.fp_${{prec}}.celltype_${{cell}}.input_${{tmp_param[0]}}.nneu_${{nneu}}\\n'''.format(version=version))\n",
    "            f.write('''                #iterate over FW BW\n",
    "                for ctype in calibrate forward backward; do\n",
    "\n",
    "                    #profile string\n",
    "                    profilestring=\"/usr/common/software/cuda/11.0.167/bin/nv-nsight-cu-cli \\\\\n",
    "                    --profile-from-start off --metrics ${metrics} --csv --kernel-base demangled\"\n",
    "\n",
    "                    if [ $enable_xla == \"xla\" ];then\n",
    "                        ${sruncmd} ${profilestring} $(which python) -u ./$script \\\\\n",
    "                            --input_tensor_shape ${input_tensor_shape} \\\\\n",
    "                            --cell_type ${cell} \\\\\n",
    "                            --n_neurons ${nneu} \\\\\n",
    "                            --dtype float${prec} \\\\\n",
    "                            --num_iterations ${num_iter} \\\\\n",
    "                            --num_warmups ${num_warmup} \\\\\n",
    "                            --enable_xla \\\\\n",
    "                            --compute_type ${ctype} 2>&1 > out.${outputstr}.pass_${ctype}.${enable_xla}\n",
    "                    else\n",
    "                        ${sruncmd} ${profilestring} $(which python) -u ./$script \\\\\n",
    "                            --input_tensor_shape ${input_tensor_shape} \\\\\n",
    "                            --cell_type ${cell} \\\\\n",
    "                            --n_neurons ${nneu} \\\\\n",
    "                            --dtype float${prec} \\\\\n",
    "                            --num_iterations ${num_iter} \\\\\n",
    "                            --num_warmups ${num_warmup} \\\\\n",
    "                            --compute_type ${ctype} 2>&1 > out.${outputstr}.pass_${ctype}.${enable_xla}\n",
    "                    fi\n",
    "\n",
    "                done\n",
    "            done\n",
    "    done\n",
    "done\\n''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
